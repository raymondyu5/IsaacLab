seed: 42

# epoch * n_steps * nenvs: 500Ã—512*8*8
n_timesteps: 163840000000000
policy: "MlpPolicy"
buffer_size: 1_000_000
batch_size: 2048
policy_kwargs: "dict(net_arch=[256, 128, 64])"
learning_starts: 2000 #100000
gradient_steps: 16
tau: 0.002
gamma: 0.98

use_residual_schedule: False
residual_schedule_horizon: 10
max_residual_schedule: 500
init_buffer: False
replay_buffer_kwargs: {}