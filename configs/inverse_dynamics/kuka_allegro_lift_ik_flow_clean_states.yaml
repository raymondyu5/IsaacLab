# State representation: s_t = [q_t, q_{t-1}, k_obj,t, k_obj,{t-1}]
#   - q_t: current robot joint positions (23 dims)
#   - q_{t-1}: previous robot joint positions (23 dims)
#   - k_obj,t: current object pose (7 dims)
#   - k_obj,{t-1}: previous object pose (7 dims)
# Total: 60 dims
model:
  _target_: generative_policies.inverse_dynamics.FlowInverseDynamics
  name: kuka_allegro_lift_ik_flow_id_clean_states
  action_dim: 22  # IK arm (6D: position + axis-angle) + Allegro hand (16D joints) = 22 DOF
  obs_dim: 60

  # Flow model architecture - scaled for smaller state space
  diffusion_step_embed_dim: 64
  down_dims: [128, 256, 512]
  num_inference_steps: 100     # Number of ODE integration steps during inference

  use_spectral_norm: false

  device: cuda
  checkpoint_path: null  # Set to path to resume from checkpoint

training:
  num_epochs: 1500
  batch_size: 512
  learning_rate: 0.0003
  device: cuda
  val_split: 0.0
  save_every_n_epochs: 20

  # Regularization
  weight_decay: 0.0001       # 1e-4 (L2 regularization)
  grad_clip: 1.0             # Gradient clipping threshold

  # Learning rate scheduling
  lr_scheduler: cosine
  warmup_epochs: 20

  # Early stopping
  early_stopping_patience: 100

  # Data preprocessing
  normalize_data: true

  # Performance optimization
  use_mixed_precision: true  # Enable mixed precision training on GPU

data:
  filter_success_only: false
  min_reward_threshold: null