model:
  _target_: generative_policies.inverse_dynamics.FlowInverseDynamics
  name: shadow_hand_flow_id
  action_dim: 23  # Kuka (7) + Allegro (16) = 23 DOF
  obs_dim: 170    # Full observation space

  diffusion_step_embed_dim: 64
  down_dims: [64, 128, 256]
  num_inference_steps: 10
  device: cuda
  checkpoint_path: null  # Set to path to resume from checkpoint

training:
  num_epochs: 1000
  batch_size: 256
  learning_rate: 0.001  # 1e-3
  device: cuda
  val_split: 0.2
  save_every_n_epochs: 10

  weight_decay: 0.0001  # 1e-4 (L2 regularization)
  grad_clip: 1.0        # Gradient clipping threshold (0 to disable)

  lr_scheduler: cosine  # Options: cosine, plateau, step, none
  warmup_epochs: 10

  early_stopping_patience: 0  # Set to 0 to disable

  normalize_data: true

  use_mixed_precision: true

data:
  filter_success_only: false  # Only use successful episodes
  min_reward_threshold: null  # Minimum episode reward (null to disable)
